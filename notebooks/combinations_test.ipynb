{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREAMBLE\n",
    "# system imports, set proto-models paths\n",
    "import sys\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent.as_posix()))\n",
    "sys.path.insert(0, str(Path.cwd().parent.parent.as_posix()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from combinations import pseudo_distribution, pseudo_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathfinder to plot bam and result example\n",
    "import pathfinder as pf\n",
    "from pathfinder import plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting\n",
    "from scipy.stats import norm, chi2, lognorm\n",
    "from iminuit import Minuit\n",
    "from iminuit.cost import UnbinnedNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams['text.kerning_factor'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input slhafile\n",
    "slhafile = '../inputFiles/slha/gluino_squarks.slha'\n",
    "bd_path = 'official'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAM Plotting\n",
    "def plot_bam(bam: dict, weights: dict) -> None:\n",
    "    bw = pseudo_distribution.get_bam_weight(bam, weights)\n",
    "    weights = bw['weights']\n",
    "    if min(weights) < 0.0:\n",
    "        offset = abs(min(weights)) + 1\n",
    "        weights += offset\n",
    "    bam = pf.BinaryAcceptance(bw['bam'], weights=weights)\n",
    "    result = pf.WHDFS(bam, ignore_subset=True)\n",
    "    result.find_paths(verbose=False)\n",
    "    plot_results.plot(bam, result=result, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get proper result at model point defined by input file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = pseudo_gen.get_llr_at_point(slhafile, data_base=bd_path)\n",
    "exp_data = pseudo_gen.get_llr_at_point(slhafile, data_base=bd_path, expected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the proper result BAM with top 10 paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bam(real_data['bam'], real_data['weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get 500pseudo results under the SM hypothesis at model point defined by input file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The results are returned as a list of weights and overlaps:\n",
    "\n",
    "$\\rightarrow$ {'weights': {'label': [weight]}, 'bam': {lebel: {set of non overlapping labels}}}\n",
    "\n",
    "Where each weight is defined as: $w_i = -2 log_e\\left[ \\frac{\\mathrm{L}(\\mu=0|\\theta)}{\\mathrm{L}(\\mu=1|\\theta)} \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_data_path = Path('pseudo_data.pickle')\n",
    "if pseudo_data_path.exists():\n",
    "    with open(pseudo_data_path, 'rb') as handle:\n",
    "        pseudo_data = pickle.load(handle)\n",
    " \n",
    "else:\n",
    "    pseudo_data = pseudo_gen.get_pseudo_llr(slhafile, data_base=bd_path, bootstrap_num=500, proc=4)\n",
    "    with open(pseudo_data_path, 'wb') as handle:\n",
    "        pickle.dump(pseudo_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "len(pseudo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find best sets of combinations for both the real and pseudo data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_res = pseudo_distribution.find_best_sets([real_data], num_cor=1)\n",
    "exp_res = pseudo_distribution.find_best_sets([exp_data], num_cor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_res_sets = pseudo_distribution.find_best_sets(pseudo_data, num_cor=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate the results\n",
    "\n",
    "##### $x^\\prime = \\sum_i^N w_i $ - (N - 1)\n",
    "\n",
    "##### $x = \\frac{x^\\prime - E[x^\\prime]}{\\sqrt{E[x^{\\prime2}] -  E[x^\\prime]^2}} = \\frac{x^\\prime - \\mu_{x^\\prime}}{ \\sigma_{x^\\prime}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lengths = np.array([len(item['best']) for _, item in pseudo_res_sets.items()])\n",
    "pseudo_res = np.array([item['weight'] for _, item in pseudo_res_sets.items()])\n",
    "\n",
    "\n",
    "expected = (sum([exp_data['weights'][key] - 1  for key in real_res[0]['best']]) + 1)\n",
    "pseudo_rescale = pseudo_res\n",
    "best_rescale = real_res[0]['weight']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fid unbinned data to pdf\n",
    "def data_fit(pseudo_rescale,  df=3, loc=0, scale=1) -> Minuit:\n",
    "    def wrap_pdf(x, df, loc, scale):\n",
    "        return chi2.pdf((x - loc)/scale, df=df)/scale\n",
    "    nll = UnbinnedNLL(pseudo_rescale, wrap_pdf)\n",
    "    im_fit = Minuit(nll, df, loc, scale)\n",
    "    im_fit.fixed['loc'] = False\n",
    "    im_fit.fixed['scale'] = False\n",
    "    im_fit.fixed['df'] = True\n",
    "    im_fit.scan()\n",
    "    im_fit.hesse()\n",
    "    return im_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = data_fit(pseudo_rescale, df=len(exp_res[0]['best']), loc=expected+0.6, scale=0.7)\n",
    "print(fit)\n",
    "cdf = chi2.cdf(best_rescale, df=fit.values['df'], loc=fit.values['loc'], scale=fit.values['scale'])\n",
    "print(f': Analytic {1. - cdf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax0 = plt.subplots()\n",
    "xrange = (pseudo_rescale.min() - 2, pseudo_rescale.max() + 2)\n",
    "xvals = np.linspace(*xrange, 1000)\n",
    "ax0.hist(pseudo_rescale, bins=50, color='lightblue', edgecolor='b', histtype='step', density=True,\n",
    "        label=r\"$x = \\frac{x\\ ^\\prime - \\mathcal{\\mu}}{\\mathcal{\\sigma}}$\")\n",
    "ax0.plot(xvals, chi2.pdf(xvals, df=fit.values['df'], loc=fit.values['loc'],  scale=fit.values['scale']), c='k', lw=0.5, ls='-')\n",
    "ax0.axvline(best_rescale, ls='--', color='g', lw=2, alpha=0.2, label='Real Data point')\n",
    "ax0.set_ylabel(\"Count\", fontsize=16)\n",
    "ax0.set_xlabel(r\"$P(x| \\theta)$\", fontsize=16)\n",
    "ax0.legend(loc=1, prop={'size': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot p-value (1 - CDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "pvals = np.array([np.sum((pseudo_rescale > val)) for val in pseudo_rescale])/(len(pseudo_rescale) - 1)\n",
    "# pvals2 = norm.sf(pseudo_rescale, fit.values['mu'], fit.values['sig'])\n",
    "fil_num, _, _ = ax1.hist(pvals, bins=30, color='lightblue', edgecolor='b', histtype='step', density=True, label='Histogram count')\n",
    "# fil_num0, _, _ = ax1.hist(pvals2, bins=30, color='lightblue', edgecolor='r', histtype='step', density=True, label='Analytic')\n",
    "# ax1.axhline(np.mean(fil_num), ls='--', color='r', lw=1, alpha=0.5)\n",
    "ax1.axhline(1, ls='--', color='k', lw=1, alpha=0.5)\n",
    "ax1.axvline((pseudo_rescale > best_rescale).sum()/len(pseudo_rescale-1), ls='--', color='g',\n",
    "            lw=2, alpha=0.5, label='p-value, Real Data')\n",
    "ax1.set_ylabel(r\"$Count$\", fontsize=16)\n",
    "ax1.set_xlabel(r\"$\\mathrm{P}(X \\geq x)$\", fontsize=16)\n",
    "ax1.legend(loc=2, prop={'size': 14})\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TACO_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
